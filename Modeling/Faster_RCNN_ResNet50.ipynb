{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleaned Faster-R-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBmQYc5Jxi_W",
        "colab_type": "text"
      },
      "source": [
        "# **1) Load tensorflow and check GPU**\n",
        "Force Google Colab to use Tensorflow 1.X and check if tensorflow can connect to Colab's GPU.\n",
        "If no GPU can be found, please check *Edit* -> *Settings* and select \"GPU\" as hardware accelerator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ttvtUsrDIuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tensorflow-gpu==1.15\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7vfyxwsx1WT",
        "colab_type": "text"
      },
      "source": [
        "# **2) Install Tensorflow Object Detection API**\n",
        "The main purpose of this snippet is to clone the [Tensorflow Models](https://github.com/tensorflow/models.git) repository. Additionally, a few additional packages are required and installed by pip. In the last step, the cloned packages are added to the python path.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN3O5w6QDeG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf_slim\n",
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "%cd /content/models/research\n",
        "\n",
        "#Fixes a common bug in Tensorflow Object Detection API\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "#Add Tensorflow model to python environment\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uKBl9mCzuEa",
        "colab_type": "text"
      },
      "source": [
        "# **3) Select pretrained model**\n",
        "For easier evaluation of different models, different pretrained models from the [Object Detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md) have been preconfigured.\n",
        "\n",
        "- *model_name*: file name of the model tar.gzip as given in the Tensorflow Model Zoo\n",
        "- *pipeline_file*: According pipeline file\n",
        "- *batch_size*: Highest batch size that doesn't exceed GPU memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irh-lrS-PAT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training steps.\n",
        "num_steps = 6000  # 200000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    },\n",
        "    'faster_rcnn_resnet50': {\n",
        "        'model_name': 'faster_rcnn_resnet50_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_resnet50_coco.config',\n",
        "        'batch_size': 12\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "selected_model = 'faster_rcnn_resnet50'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR4vkAcVhHOQ",
        "colab_type": "text"
      },
      "source": [
        "# **4) Download pretrained model**\n",
        "Download the selected pretrained model from tensorflow and move it to the right place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA6QTs-ngxnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "#Check if models has already been downloaded\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "#Unzip\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "\n",
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OVxQVMJhE1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "27a6c6ba-1d80-4b4f-8252-72c8deeb960b"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paSUZ2sehkGG",
        "colab_type": "text"
      },
      "source": [
        "## **5) Load training data**\n",
        "The model requires three files:\n",
        "\n",
        "*   *train.record:* TFRecord file holding all examples for training.\n",
        "*   *test.record:* TFRecord file holding examples for testing.\n",
        "*   *label_map.pbtxt:* JSON file mapping class names to class IDs.\n",
        "\n",
        "Since these files are pretty large and Google Colab deletes custom data after disconnection, these files are stored on Google Drive that gets mounted into the Colab environment. Therefore it is required to provide this Colab notebook a one-time key to access the Drive. Please follow the instructions given when executing this cell.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRrCSXcn8h3j",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN5OhLPWhp0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set path variables to test and train data as well as labels.\n",
        "train_record_fname = '/content/drive/My Drive/TFRecord/Max_800px/train.record'\n",
        "test_record_fname = '/content/drive/My Drive/TFRecord/Max_800px/test.record'\n",
        "label_map_pbtxt_fname = '/content/drive/My Drive/TFRecord/Max_800px/label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQglnsJFhLGV",
        "colab_type": "text"
      },
      "source": [
        "## **6) Configuring Training Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VH9BfMwhOPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Load model's pipeline file\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emSgR-rC1lyg",
        "colab_type": "text"
      },
      "source": [
        "Each pretrained Tensorflow model comes with a so called [pipeline file](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/pipeline.proto) that contains the most important settings. We have to adjust this, e.g. with our batch size, input data, etc.\n",
        "\n",
        "We add the following information:\n",
        "*   Path to fine_tune_checkpoint (file where model parameters are stored)\n",
        "*   Path to train and test data (as configured above)\n",
        "*   Path to label map (as configured above)\n",
        "*   Batch_size\n",
        "*   Training_steps\n",
        "*   Evaluation_steps\n",
        "*   Number of classes (right now just stairs = 1 class)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0KwND1hhY6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    num_classes = 1\n",
        "\n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J41ALPbodP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print adjusted pipeline\n",
        "!cat {pipeline_fname}\n",
        "\n",
        "model_dir = 'training/'\n",
        "\n",
        "# Remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_JX0v0mrfyL",
        "colab_type": "text"
      },
      "source": [
        "# **7) Initialize Tensorboard**\n",
        "[Tensorboard](https://www.tensorflow.org/tensorboard) is a great tool to visualize the training model, important metrics and examplatory results.\n",
        "\n",
        "Unfortunately, we cannot access it directly through Google Colab and have to use a tunnel. [Ngrok](https://ngrok.com/product) offers such a tunnel.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs_fIXYTrfXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and unzip Ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# Initialize tensorboard and expose it to port 6000\n",
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mqROmNRsAaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Expose port 6000 (used by tensorboard) via ngrok tunnel to public\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koYj3BLjsCxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "26d8abd1-58fc-485f-ccb8-0c49eb70dae0"
      },
      "source": [
        "# Print public address to exposed tensorboard\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://0294338ce352.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ic7tQVFsGrB",
        "colab_type": "text"
      },
      "source": [
        "# **8) Train model**\n",
        "This cell finally trains the model with the provided training data. Real time results can be access via Tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FnHPL4XsJxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRHdXG1p4F2D",
        "colab_type": "text"
      },
      "source": [
        "## **9) Export trained model**\n",
        "There are to files to be exported:\n",
        "\n",
        "\n",
        "1.   The inference graph\n",
        "2.   The model.pb file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8SX1qGR4K9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Export to new folder \"fine_tuned_model\"\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "# Find last tensorflow checkpoint file in model directory\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "\n",
        "# export graph by using a Tensorflow API script\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkLJV1Q_4r1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if we really exported something\n",
        "!ls {output_directory}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W3cgYJU4vE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWNqgiiB5DNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if we really exported something\n",
        "!ls -alh {pb_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4y5O_yBCdXI",
        "colab_type": "text"
      },
      "source": [
        "## **10) Download model files**\n",
        "Otherwise, one can also copy the folder *fine_tuned_model* to the Google Drive. Warning: After closing the Colab (or alternatively some inactive time) all data in this Colab gets lost!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzSVFD96nKH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/file.zip /content/models/research/fine_tuned_model/\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}